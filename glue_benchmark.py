# -*- coding: utf-8 -*-
"""GLUE Benchmark

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r4WJDzvHfQX-t4TVlmNXRVDtSiEcyi-i
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding
from datasets import Dataset
from datasets import load_dataset

!pip install evaluate
import evaluate

#Load the model
model_name = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)

#Load dataset(GLUE)
task = "sst2"
dataset = load_dataset("glue", task)

#Preprocess the dataset
def Preprocess_function(examples):
    return tokenizer(examples["sentence"], truncation=True, padding="max_length", max_length=128)
encoded_dataset = dataset.map(Preprocess_function, batched=True)
# Load evaluation metric
metric = evaluate.load("glue", task)

# Define a function compute metric
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)

# Create a DataCollator for dynamic padding
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# Prepare evaluation arguments
training_args = TrainingArguments(
    output_dir="./results",
    learning_rate=2e-5,
    per_device_eval_batch_size=64,
    logging_dir="./logs",
    do_train=False,
    do_eval=True
)

# Initialize trainer
trainer = Trainer(
    model=model,
    args=training_args,
    eval_dataset=encoded_dataset["validation"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
)

# Run evaluation
results = trainer.evaluate()
print(results)

#Filter GLUE specific Metric
excluded_metrics = ["eval_loss", "eval_runtime", "eval_samples_per_second", "eval_steps_per_second", "eval_model_prepare_time"]
glue_metrics = {k: v for k, v in results.items() if k not in excluded_metrics}

# Convert GLUE metrics to a DataFrame for visualization
results_df = pd.DataFrame.from_dict(glue_metrics, orient="index", columns=["Value"])
results_df = results_df.reset_index()
results_df.columns = ["Metric", "Value"]
print("Filtered Results for Graph:", results_df)

# Plot the GLUE metrics
plt.figure(figsize=(10, 6))
sns.barplot(x="Metric", y="Value", data=results_df, palette="viridis")
plt.title(f"GLUE Evaluation Results for Task: {task.upper()}", fontsize=16)
plt.xlabel("Metrics", fontsize=14)
plt.ylabel("Values", fontsize=14)
plt.xticks(rotation=45, fontsize=12)
plt.show()











